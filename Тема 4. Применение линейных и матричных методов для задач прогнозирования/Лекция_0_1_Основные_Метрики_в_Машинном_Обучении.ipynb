{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5dj80BX/v3z2FKnBcq9IE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/AnalyzData-2024-EDA/blob/main/%D0%9B%D0%B5%D0%BA%D1%86%D0%B8%D1%8F_0_1_%D0%9E%D1%81%D0%BD%D0%BE%D0%B2%D0%BD%D1%8B%D0%B5_%D0%9C%D0%B5%D1%82%D1%80%D0%B8%D0%BA%D0%B8_%D0%B2_%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%BC_%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лекция: Основные Метрики в Машинном Обучении\n",
        "\n",
        "## Введение\n",
        "\n",
        "Метрики являются ключевыми инструментами для оценки качества моделей машинного обучения (ML). Они позволяют понять, насколько хорошо модель предсказывает данные и помогает в сравнении различных моделей. В данной лекции мы рассмотрим основные метрики, используемые для оценки моделей классификации и регрессии.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BjxqguHy6IeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В задачах регрессии целью является предсказание непрерывного значения, а не метки класса, как в задачах классификации. Для оценки качества моделей регрессии существует несколько основных метрик.\n",
        "\n",
        "## Основные метрики для задач регрессии\n",
        "\n",
        "#### 1. Средняя абсолютная ошибка (Mean Absolute Error, MAE)\n",
        "\n",
        "MAE измеряет среднюю абсолютную разницу между предсказанными и фактическими значениями.\n",
        "\n",
        "Формула MAE:\n",
        "\n",
        "$$\n",
        "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
        "$$\n",
        "\n",
        "где:\n",
        "- \\( y_i \\) — истинное значение для i-го наблюдения,\n",
        "- \\( \\hat{y}_i \\) — предсказанное значение для i-го наблюдения,\n",
        "- \\( n \\) — количество наблюдений.\n",
        "\n",
        "MAE измеряется в тех же единицах, что и исходные данные, что делает его легко интерпретируемым.\n",
        "\n",
        "#### 2. Среднеквадратичная ошибка (Mean Squared Error, MSE)\n",
        "\n",
        "MSE измеряет среднюю квадратичную разницу между предсказанными и фактическими значениями. Она более чувствительна к большим отклонениям (выбросам) по сравнению с MAE.\n",
        "\n",
        "Формула MSE:\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "MSE штрафует большие ошибки сильнее, чем маленькие, из-за возведения разницы в квадрат.\n",
        "\n",
        "#### 3. Корень из среднеквадратичной ошибки (Root Mean Squared Error, RMSE)\n",
        "\n",
        "RMSE является квадратным корнем из MSE и выражается в тех же единицах, что и исходные данные.\n",
        "\n",
        "Формула RMSE:\n",
        "\n",
        "$$\n",
        "\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "RMSE представляет собой более интерпретируемую метрику ошибки, чем MSE, так как её значения сопоставимы с оригинальными данными.\n",
        "\n",
        "#### 4. Коэффициент детерминации (R² Score)\n",
        "\n",
        "R² Score, или коэффициент детерминации, измеряет долю дисперсии зависимой переменной, которая объясняется моделью. Он также известен как коэффициент детерминации.\n",
        "\n",
        "Формула R² Score:\n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $ y_i $— истинное значение для i-го наблюдения,\n",
        "- \\( \\hat{y}_i \\) — предсказанное значение для i-го наблюдения,\n",
        "- \\( \\bar{y} \\) — среднее значение истинных значений,\n",
        "- \\( n \\) — количество наблюдений.\n",
        "\n",
        "R² Score показывает, насколько хорошо модель соответствует данным. Значение R² Score может варьироваться от 0 до 1, где 1 указывает на идеальное предсказание, а 0 — на то, что модель не лучше, чем простое среднее.\n",
        "\n",
        "### Примеры\n",
        "\n",
        "#### Пример 1: Оценка модели регрессии\n",
        "\n",
        "Предположим, у нас есть следующие данные о предсказаниях модели и истинных значениях:\n",
        "\n",
        "- Истинные значения: [3, 5, 2, 7]\n",
        "- Предсказанные значения: [2.5, 5.3, 2.1, 7.8]\n",
        "\n",
        "Вычислим основные метрики:\n",
        "\n",
        "1. MAE:\n",
        "\n",
        "$$\n",
        "\\text{MAE} = \\frac{1}{4} (|3 - 2.5| + |5 - 5.3| + |2 - 2.1| + |7 - 7.8|) = \\frac{1}{4} (0.5 + 0.3 + 0.1 + 0.8) = \\frac{1.7}{4} = 0.425\n",
        "$$\n",
        "\n",
        "2. MSE:\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{4} ((3 - 2.5)^2 + (5 - 5.3)^2 + (2 - 2.1)^2 + (7 - 7.8)^2) = \\frac{1}{4} (0.25 + 0.09 + 0.01 + 0.64) = \\frac{0.99}{4} = 0.2475\n",
        "$$\n",
        "\n",
        "3. RMSE:\n",
        "\n",
        "$$\n",
        "\\text{RMSE} = \\sqrt{0.2475} \\approx 0.497\n",
        "$$\n",
        "\n",
        "4. R² Score:\n",
        "\n",
        "Сначала вычислим среднее значение истинных значений $ \\bar{y} $:\n",
        "\n",
        "$$\n",
        "\\bar{y} = \\frac{3 + 5 + 2 + 7}{4} = 4.25\n",
        "$$\n",
        "\n",
        "Теперь вычислим R² Score:\n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\sum_{i=1}^{4} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{4} (y_i - \\bar{y})^2} = 1 - \\frac{0.99}{(3 - 4.25)^2 + (5 - 4.25)^2 + (2 - 4.25)^2 + (7 - 4.25)^2} = 1 - \\frac{0.99}{1.5625 + 0.5625 + 5.0625 + 7.5625} = 1 - \\frac{0.99}{14.75} \\approx 0.93\n",
        "$$\n",
        "\n",
        "**Заключение.**\n",
        "Выбор метрики зависит от конкретной задачи и требований к модели. Например, если важно минимизировать влияние выбросов, то лучше использовать MAE или RMSE. Если необходимо понять, какую часть дисперсии переменной объясняет модель, полезно использовать R² Score. Все эти метрики позволяют оценить качество модели и сравнивать различные варианты моделей между собой."
      ],
      "metadata": {
        "id": "7tdVmyTU6ZjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В дополнение к основным метрикам, таким как MAE, MSE, RMSE и R² Score, существуют и другие метрики, которые могут быть полезны в различных ситуациях при оценке моделей регрессии. Рассмотрим несколько дополнительных метрик:\n",
        "\n",
        "## Дополнительные метрики для задач регрессии\n",
        "\n",
        "#### 1. Средняя абсолютная процентная ошибка (Mean Absolute Percentage Error, MAPE)\n",
        "\n",
        "MAPE измеряет среднюю абсолютную процентную разницу между предсказанными и фактическими значениями. Эта метрика полезна для оценки точности модели в процентах относительно исходных значений.\n",
        "\n",
        "Формула MAPE:\n",
        "\n",
        "$$\n",
        "\\text{MAPE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| \\times 100\\%\n",
        "$$\n",
        "\n",
        "где:\n",
        "- \\( y_i \\) — истинное значение для i-го наблюдения,\n",
        "- \\( \\hat{y}_i \\) — предсказанное значение для i-го наблюдения,\n",
        "- \\( n \\) — количество наблюдений.\n",
        "\n",
        "#### 2. Средняя квадратичная логарифмическая ошибка (Mean Squared Logarithmic Error, MSLE)\n",
        "\n",
        "MSLE измеряет среднюю квадратичную разницу между логарифмами предсказанных и истинных значений. Она полезна, когда предсказываемые значения имеют широкий диапазон.\n",
        "\n",
        "Формула MSLE:\n",
        "\n",
        "$$\n",
        "\\text{MSLE} = \\frac{1}{n} \\sum_{i=1}^{n} (\\log(1 + y_i) - \\log(1 + \\hat{y}_i))^2\n",
        "$$\n",
        "\n",
        "#### 3. Метрика Huber\n",
        "\n",
        "Метрика Huber является комбинацией MSE и MAE и является более устойчивой к выбросам по сравнению с MSE. Она вычисляется по следующей формуле:\n",
        "\n",
        "$$\n",
        "\\text{Huber}(y, \\hat{y}) = \\begin{cases}\n",
        "\\frac{1}{2}(y - \\hat{y})^2, & \\text{если } |y - \\hat{y}| \\leq \\delta \\\\\n",
        "\\delta(|y - \\hat{y}| - \\frac{1}{2}\\delta), & \\text{иначе}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "где \\( \\delta \\) — параметр, определяющий порог для перехода от квадратичной ошибки к линейной.\n",
        "\n",
        "#### 4. Коэффициент Эффективности Пирсона (Pearson's Efficiency Coefficient)\n",
        "\n",
        "Коэффициент Эффективности Пирсона измеряет корреляцию между предсказанными и истинными значениями.\n",
        "\n",
        "Формула Коэффициента Эффективности Пирсона:\n",
        "\n",
        "$$\n",
        "\\text{Pearson's Efficiency} = \\frac{\\text{cov}(\\hat{y}, y)}{\\sqrt{\\text{var}(\\hat{y}) \\cdot \\text{var}(y)}}\n",
        "$$\n",
        "\n",
        "где:\n",
        "- \\( \\text{cov}(\\hat{y}, y) \\) — ковариация между предсказанными и истинными значениями,\n",
        "- \\( \\text{var}(\\hat{y}) \\) — дисперсия предсказанных значений,\n",
        "- \\( \\text{var}(y) \\) — дисперсия истинных значений.\n",
        "\n",
        "### Когда использовать дополнительные метрики\n",
        "\n",
        "- **MAPE** полезна, когда важна относительная ошибка по отношению к исходным данным.\n",
        "- **MSLE** полезна, когда данные имеют большой разброс и различную величину.\n",
        "- **Huber** полезна, когда необходима устойчивость к выбросам в данных.\n",
        "- **Коэффициент Эффективности Пирсона** полезен для оценки корреляции между предсказанными и истинными значениями.\n",
        "\n",
        "Выбор конкретной метрики зависит от особенностей данных, целей моделирования и требований к точности оценки."
      ],
      "metadata": {
        "id": "U-vsWCjd6hM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Метрики для задач классификации\n",
        "\n",
        "\n",
        "#### Введение в метрики оценки качества классификации\n",
        "\n",
        "В задачах классификации важно не только обучить модель, но и корректно оценить её качество. Для этого используются различные метрики, которые помогают оценить, насколько хорошо модель справляется с предсказанием классов.\n",
        "\n",
        "#### Основные метрики для бинарной классификации\n",
        "\n",
        "##### 1. **Матрица ошибок (Confusion Matrix)**\n",
        "\n",
        "Матрица ошибок является основой для вычисления многих метрик классификации. Она показывает количество верно и неверно классифицированных примеров.\n",
        "\n",
        "Пусть:\n",
        "- \\( TP \\) (True Positive) — количество верно предсказанных положительных примеров,\n",
        "- \\( TN \\) (True Negative) — количество верно предсказанных отрицательных примеров,\n",
        "- \\( FP \\) (False Positive) — количество неверно предсказанных положительных примеров,\n",
        "- \\( FN \\) (False Negative) — количество неверно предсказанных отрицательных примеров.\n",
        "\n",
        "Тогда матрица ошибок выглядит следующим образом:\n",
        "\n",
        "\\[\n",
        "\\begin{array}{|c|c|}\n",
        "\\hline\n",
        "\\text{Истинное} & \\text{Предсказанное} \\\\\n",
        "\\text{значение} & \\\\\n",
        "\\hline\n",
        "\\text{Positive} & TP \\quad FP \\\\\n",
        "\\hline\n",
        "\\text{Negative} & FN \\quad TN \\\\\n",
        "\\hline\n",
        "\\end{array}\n",
        "\\]\n",
        "\n",
        "##### 2. **Accuracy (Точность)**\n",
        "\n",
        "Accuracy — это доля правильных ответов по всем примерам:\n",
        "\n",
        "\\[\n",
        "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "\\]\n",
        "\n",
        "##### 3. **Precision (Точность)**\n",
        "\n",
        "Precision — доля правильно предсказанных положительных примеров среди всех положительных предсказаний:\n",
        "\n",
        "\\[\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "\\]\n",
        "\n",
        "##### 4. **Recall (Полнота)**\n",
        "\n",
        "Recall — доля правильно предсказанных положительных примеров среди всех истинно положительных примеров:\n",
        "\n",
        "\\[\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "\\]\n",
        "\n",
        "##### 5. **F1-мера**\n",
        "\n",
        "F1-мера — гармоническое среднее точности и полноты, используется для балансировки между ними:\n",
        "\n",
        "\\[\n",
        "\\text{F1} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "\\]\n",
        "\n",
        "#### Пример вычисления метрик на простом наборе данных\n",
        "\n",
        "Рассмотрим набор данных с двумя классами (Positive и Negative) и их предсказаниями:\n",
        "\n",
        "\\[\n",
        "\\begin{array}{|c|c|}\n",
        "\\hline\n",
        "\\text{Истинное} & \\text{Предсказанное} \\\\\n",
        "\\text{значение} & \\\\\n",
        "\\hline\n",
        "\\text{Positive} & 30 \\quad 10 \\\\\n",
        "\\hline\n",
        "\\text{Negative} & 5 \\quad 55 \\\\\n",
        "\\hline\n",
        "\\end{array}\n",
        "\\]\n",
        "\n",
        "Где \\( TP = 30 \\), \\( FP = 10 \\), \\( FN = 5 \\), \\( TN = 55 \\).\n",
        "\n",
        "Вычислим метрики:\n",
        "\n",
        "- Accuracy: \\( \\frac{30 + 55}{30 + 10 + 5 + 55} = \\frac{85}{100} = 0.85 \\)\n",
        "- Precision: \\( \\frac{30}{30 + 10} = \\frac{30}{40} = 0.75 \\)\n",
        "- Recall: \\( \\frac{30}{30 + 5} = \\frac{30}{35} \\approx 0.857 \\)\n",
        "- F1-мера: \\( 2 \\cdot \\frac{0.75 \\cdot 0.857}{0.75 + 0.857} \\approx 0.8 \\)\n",
        "\n",
        "#### Заключение\n",
        "\n",
        "Метрики классификации играют важную роль в оценке качества моделей машинного обучения. Выбор подходящей метрики зависит от специфики задачи и требований к результатам. Важно понимать, как каждая метрика отражает разные аспекты качества классификации и как их интерпретировать в конкретных случаях."
      ],
      "metadata": {
        "id": "hUF_wX3_6mur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дополнительно к основным метрикам (Accuracy, Precision, Recall, F1-мера) существует ряд других метрик, которые могут быть полезны в различных сценариях классификации. Рассмотрим некоторые из них:\n",
        "\n",
        "##### 6. **ROC-кривая и AUC-ROC**\n",
        "\n",
        "ROC-кривая (Receiver Operating Characteristic curve) показывает зависимость между долей истинно положительных классификаций (True Positive Rate, TPR) и долей ложно положительных классификаций (False Positive Rate, FPR) при варьировании порога классификации.\n",
        "\n",
        "- **TPR (True Positive Rate или Recall)**: \\( \\text{TPR} = \\frac{TP}{TP + FN} \\)\n",
        "- **FPR (False Positive Rate)**: \\( \\text{FPR} = \\frac{FP}{FP + TN} \\)\n",
        "\n",
        "AUC-ROC (Area Under the ROC Curve) — это площадь под ROC-кривой, которая представляет собой общую производительность классификатора при всех возможных значениях порога.\n",
        "\n",
        "##### 7. **PR-кривая и AUC-PR**\n",
        "\n",
        "PR-кривая (Precision-Recall curve) показывает зависимость между точностью (Precision) и полнотой (Recall) при варьировании порога классификации.\n",
        "\n",
        "- AUC-PR (Area Under the PR Curve) — площадь под PR-кривой, оценивает общую производительность классификатора при разных значениях порога.\n",
        "\n",
        "##### 8. **F-мера с весами**\n",
        "\n",
        "В некоторых задачах может быть необходимо учитывать различную важность точности и полноты. В таких случаях используют F-меру с весами, где задаются веса для Precision и Recall:\n",
        "\n",
        "\\[\n",
        "\\text{F}_{\\beta} = (1 + \\beta^2) \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\beta^2 \\cdot \\text{Precision} + \\text{Recall}}\n",
        "\\]\n",
        "\n",
        "Здесь \\( \\beta \\) определяет вес между Precision и Recall (обычно \\( \\beta > 1 \\) увеличивает вес Recall).\n",
        "\n",
        "##### 9. **Матрика ошибок для мультиклассовой классификации**\n",
        "\n",
        "Для мультиклассовой классификации также используется матрица ошибок, которая показывает количество верно и неверно классифицированных примеров для каждого класса.\n",
        "\n",
        "##### 10. **Макро- и микро-усреднение**\n",
        "\n",
        "Макро-усреднение (Macro-average) вычисляет метрику независимо для каждого класса, а затем усредняет их. Микро-усреднение (Micro-average) вычисляет общие TP, FP и FN по всем классам, а затем вычисляет метрику.\n",
        "\n",
        "Эти методы полезны при несбалансированных классах.\n",
        "\n",
        "##### 11. **Log Loss (Логарифмическая функция потерь)**\n",
        "\n",
        "Log Loss используется для оценки качества вероятностных прогнозов классификационной модели:\n",
        "\n",
        "\\[\n",
        "\\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\n",
        "\\]\n",
        "\n",
        "где \\( y_i \\) — истинное значение целевой переменной, \\( p_i \\) — вероятность, предсказанная моделью для класса.\n",
        "\n",
        "##### 12. **Specificity (Специфичность)**\n",
        "\n",
        "Специфичность показывает долю верно предсказанных отрицательных примеров среди всех реальных отрицательных примеров:\n",
        "\n",
        "\\[\n",
        "\\text{Specificity} = \\frac{TN}{TN + FP}\n",
        "\\]\n",
        "\n",
        "Эта метрика особенно полезна в задачах с дисбалансом классов.\n",
        "\n",
        "#### Заключение\n",
        "\n",
        "Выбор подходящей метрики зависит от конкретной задачи и требований к классификационной модели. Важно учитывать специфику данных, особенности классов, и желаемые характеристики предсказаний при выборе метрики оценки качества модели машинного обучения."
      ],
      "metadata": {
        "id": "ZbXT2JTM7MaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "103YkbJx8HFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Метрики для задач кластеризации\n",
        "\n",
        "\n",
        "#### Введение в задачу кластеризации\n",
        "\n",
        "Задача кластеризации в машинном обучении заключается в группировке объектов данных в кластеры таким образом, чтобы объекты в одном кластере были более похожи друг на друга, чем на объекты из других кластеров. Основные метрики для оценки качества кластеризации помогают оценить, насколько эффективно алгоритм справляется с этой задачей.\n",
        "\n",
        "#### Основные метрики для кластеризации\n",
        "\n",
        "1. **Adjusted Rand Index (ARI)**\n",
        "\n",
        "   ARI измеряет сходство между двумя разбиениями данных, учитывая случайное согласование. Он вычисляется с использованием таблицы сопряженности, которая показывает, сколько пар объектов попали в одинаковые кластеры в обоих разбиениях.\n",
        "\n",
        "   Формула для ARI:\n",
        "   \\[\n",
        "   ARI = \\frac{\\sum_{ij} \\binom{n_{ij}}{2} - [\\sum_{i} \\binom{a_i}{2} \\sum_{j} \\binom{b_j}{2}] / \\binom{n}{2}}{\\frac{1}{2} [\\sum_{i} \\binom{a_i}{2} + \\sum_{j} \\binom{b_j}{2}] - [\\sum_{i} \\binom{a_i}{2} \\sum_{j} \\binom{b_j}{2}] / \\binom{n}{2}}\n",
        "   \\]\n",
        "   Где:\n",
        "   - \\( n_{ij} \\) - количество пар объектов, которые попали в одинаковые кластеры в обоих разбиениях\n",
        "   - \\( a_i \\) - количество объектов в кластере \\( i \\) в первом разбиении\n",
        "   - \\( b_j \\) - количество объектов в кластере \\( j \\) во втором разбиении\n",
        "   - \\( n \\) - общее число объектов\n",
        "\n",
        "   Пример: Если у нас есть идеальное разбиение на кластеры и другое разбиение, которое сильно отличается, ARI будет близок к 1. Если разбиения случайны, ARI будет близок к 0.\n",
        "\n",
        "2. **Adjusted Mutual Information (AMI)**\n",
        "\n",
        "   AMI измеряет степень согласованности между двумя разбиениями данных, корректируя на случайное согласование. Он также использует таблицу сопряженности.\n",
        "\n",
        "   Формула для AMI:\n",
        "   \\[\n",
        "   AMI = \\frac{I(X; Y) - E[I(X; Y)]}{\\max(H(X), H(Y)) - E[I(X; Y)]}\n",
        "   \\]\n",
        "   Где:\n",
        "   - \\( I(X; Y) \\) - взаимная информация между разбиениями \\( X \\) и \\( Y \\)\n",
        "   - \\( H(X) \\), \\( H(Y) \\) - энтропии разбиений \\( X \\) и \\( Y \\)\n",
        "   - \\( E[I(X; Y)] \\) - ожидаемое значение взаимной информации для случайного разбиения\n",
        "\n",
        "   Пример: Чем выше AMI, тем более согласованы разбиения.\n",
        "\n",
        "3. **Silhouette Score**\n",
        "\n",
        "   Silhouette Score вычисляет меру того, насколько каждый объект хорошо согласуется со своим собственным кластером по сравнению с другими кластерами. Он принимает значения от -1 до 1.\n",
        "\n",
        "   Формула для Silhouette Score для объекта \\( i \\):\n",
        "   \\[\n",
        "   s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}\n",
        "   \\]\n",
        "   Где:\n",
        "   - \\( a(i) \\) - среднее расстояние от объекта \\( i \\) до всех других объектов в том же кластере\n",
        "   - \\( b(i) \\) - среднее расстояние от объекта \\( i \\) до объектов ближайшего соседнего кластера\n",
        "\n",
        "   Средний Silhouette Score для всех объектов дает общую оценку качества кластеризации.\n",
        "\n",
        "   Пример: Чем ближе Silhouette Score к 1, тем лучше кластеризация.\n",
        "\n",
        "Кроме упомянутых метрик (ARI, AMI и Silhouette Score), существует ряд других метрик, которые также используются для оценки качества кластеризации в машинном обучении. Вот некоторые из них:\n",
        "\n",
        "### Дополнительные метрики для кластеризации\n",
        "\n",
        "4. **Homogeneity, Completeness и V-measure**\n",
        "\n",
        "   Эти метрики измеряют различные аспекты качества кластеризации, учитывая только одно разбиение данных.\n",
        "\n",
        "   - **Homogeneity**: Оценивает, насколько каждый кластер состоит из объектов одного класса или разбросаны ли они по различным классам. Значение близкое к 1 указывает на хорошую гомогенность кластеров.\n",
        "   \n",
        "   - **Completeness**: Показывает, насколько объекты одного класса относятся к одному и тому же кластеру. Значение близкое к 1 указывает на высокую полноту.\n",
        "   \n",
        "   - **V-measure**: Гармоническое среднее между homogeneity и completeness. Высокое значение V-measure указывает на хорошее качество как гомогенности, так и полноты кластеризации.\n",
        "\n",
        "   Формулы для Homogeneity \\( h \\), Completeness \\( c \\) и V-measure \\( v \\):\n",
        "   \\[\n",
        "   h = 1 - \\frac{H(C|K)}{H(C)}\n",
        "   \\]\n",
        "   \\[\n",
        "   c = 1 - \\frac{H(K|C)}{H(K)}\n",
        "   \\]\n",
        "   \\[\n",
        "   v = \\frac{2 \\cdot (h \\cdot c)}{h + c}\n",
        "   \\]\n",
        "   Где:\n",
        "   - \\( H(C|K) \\) - условная энтропия классов при условии кластеров\n",
        "   - \\( H(C) \\) - энтропия классов\n",
        "   - \\( H(K|C) \\) - условная энтропия кластеров при условии классов\n",
        "   - \\( H(K) \\) - энтропия кластеров\n",
        "\n",
        "   Пример: Высокие значения homogeneity, completeness и V-measure указывают на качественную кластеризацию.\n",
        "\n",
        "5. **Davies-Bouldin Index**\n",
        "\n",
        "   DB-индекс измеряет среднее расстояние между каждым кластером и его самым близким кластером, нормализованное по размеру кластеров. Меньшие значения DB-индекса указывают на более компактные и хорошо разделенные кластеры.\n",
        "\n",
        "   Формула для DB-индекса:\n",
        "   \\[\n",
        "   DB = \\frac{1}{k} \\sum_{i=1}^{k} \\max_{j \\neq i} \\left( \\frac{\\sigma_i + \\sigma_j}{d(c_i, c_j)} \\right)\n",
        "   \\]\n",
        "   Где:\n",
        "   - \\( k \\) - количество кластеров\n",
        "   - \\( \\sigma_i \\) - среднее расстояние от центроида кластера \\( i \\) до всех точек в кластере\n",
        "   - \\( d(c_i, c_j) \\) - расстояние между центроидами кластеров \\( i \\) и \\( j \\)\n",
        "\n",
        "   Пример: Меньшие значения DB-индекса указывают на лучшую кластеризацию.\n",
        "\n",
        "6. **Calinski-Harabasz Index (также известен как Variance Ratio Criterion)**\n",
        "\n",
        "   CH-индекс измеряет отношение между суммой дисперсий внутри кластеров и между кластерами для всего набора данных. Большие значения CH-индекса соответствуют более компактным и отделенным кластерам.\n",
        "\n",
        "   Формула для CH-индекса:\n",
        "   \\[\n",
        "   CH = \\frac{\\text{Tr}(B_k)}{\\text{Tr}(W_k)} \\times \\frac{N - k}{k - 1}\n",
        "   \\]\n",
        "   Где:\n",
        "   - \\( B_k \\) - матрица разброса между кластерами\n",
        "   - \\( W_k \\) - матрица разброса внутри кластеров\n",
        "   - \\( N \\) - общее количество точек данных\n",
        "   - \\( k \\) - количество кластеров\n",
        "\n",
        "   Пример: Большие значения CH-индекса указывают на лучшую кластеризацию.\n",
        "\n",
        "### Заключение\n",
        "\n",
        "Выбор подходящей метрики зависит от конкретной задачи кластеризации, типа данных и требований к результатам. Каждая из этих метрик предоставляет информацию о различных аспектах качества кластеризации, что помогает анализировать и сравнивать результаты различных алгоритмов кластеризации.\n"
      ],
      "metadata": {
        "id": "TAFvXpsE8QAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vqRKjIxM8YgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8jaIIRv78R9c"
      }
    }
  ]
}